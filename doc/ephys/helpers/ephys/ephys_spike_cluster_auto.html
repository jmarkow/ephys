<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of ephys_spike_cluster_auto</title>
  <meta name="keywords" content="ephys_spike_cluster_auto">
  <meta name="description" content="">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html v1.5 &copy; 2003-2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../../m2html.css">
</head>
<body>
<a name="_top"></a>
<div><a href="../../../menu.html">Home</a> &gt;  <a href="../../menu.html">ephys</a> &gt; <a href="../menu.html">helpers</a> &gt; <a href="menu.html">ephys</a> &gt; ephys_spike_cluster_auto.m</div>

<!--<table width="100%"><tr><td align="left"><a href="../../../menu.html"><img alt="<" border="0" src="../../../left.png">&nbsp;Master index</a></td>
<td align="right"><a href="menu.html">Index for ephys/helpers/ephys&nbsp;<img alt=">" border="0" src="../../../right.png"></a></td></tr></table>-->

<h1>ephys_spike_cluster_auto
</h1>

<h2><a name="_name"></a>PURPOSE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong></strong></div>

<h2><a name="_synopsis"></a>SYNOPSIS <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box"><strong>function [LABELS TRIALS ISI WINDOWS]=ephys_spike_cluster_auto(SPIKEWINDOWS,SPIKETIMES,varargin) </strong></div>

<h2><a name="_description"></a>DESCRIPTION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre class="comment"></pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>CROSS-REFERENCE INFORMATION <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
This function calls:
<ul style="list-style-image:url(../../../matlabicon.gif)">
</ul>
This function is called by:
<ul style="list-style-image:url(../../../matlabicon.gif)">
<li><a href="../../../ephys/ephys_visual_sua.html" class="code" title="function ephys_visual_sua(EPHYS_DATA,HISTOGRAM,CHANNELS,varargin)">ephys_visual_sua</a>	ephys_visual_sua.m takes data generated by intan_cluster.m and stored in extracted_data.mat</li></ul>
<!-- crossreference -->



<h2><a name="_source"></a>SOURCE CODE <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre>0001 <a name="_sub0" href="#_subfunctions" class="code">function [LABELS TRIALS ISI WINDOWS]=ephys_spike_cluster_auto(SPIKEWINDOWS,SPIKETIMES,varargin)</a>
0002 <span class="comment">%</span>
0003 
0004 <span class="comment">% automated spike clustering using fuzzy c-means</span>
0005 
0006 <span class="comment">% load the information collected by outloop</span>
0007 
0008 <span class="comment">% spikewindows', rows x samples, each row is a windowed spike waveform</span>
0009 
0010 <span class="comment">% some standard spike features, spike width, height</span>
0011 
0012 <span class="comment">% we need to upsample to get a true representation of the underlying waveform</span>
0013 
0014 LABELS=[];
0015 TRIALS=[];
0016 ISI=[];
0017 WINDOWS=[];
0018 
0019 sr=25e3;
0020 interpolate=1;
0021 interpolate_fs=50e3;
0022 use_spiketime=0; <span class="comment">% use spiketime as a clustering feature (usually helps if SNR is low)</span>
0023 nparams=length(varargin);
0024 maxcoeffs=5; <span class="comment">% number of wavelet coefficients to use (sorted by KS statistic)</span>
0025 outlier_cutoff=.5; <span class="comment">% posterior probability cutoff for outliers (.6-.8 work well) [0-1, high=more aggresive]</span>
0026 
0027 <span class="keyword">if</span> mod(nparams,2)&gt;0
0028     error(<span class="string">'Parameters must be specified as parameter/value pairs!'</span>);
0029 <span class="keyword">end</span>
0030 
0031 <span class="keyword">for</span> i=1:2:nparams
0032     <span class="keyword">switch</span> lower(varargin{i})
0033         <span class="keyword">case</span> <span class="string">'sr'</span>
0034             sr=varargin{i+1};
0035         <span class="keyword">case</span> <span class="string">'interpolate'</span>
0036             interpolate=varargin{i+1};
0037         <span class="keyword">case</span> <span class="string">'interpolate_fs'</span>
0038             interpolate_fs=varargin{i+1};
0039         <span class="keyword">case</span> <span class="string">'use_spiketime'</span>
0040             spiketime=varaargin{i+1};
0041         <span class="keyword">case</span> <span class="string">'maxcoeffs'</span>
0042             maxcoeffs=varargin{i+1};
0043     <span class="keyword">end</span>
0044 <span class="keyword">end</span>
0045 
0046 <span class="comment">% need to deal with cell input (multiple trials), convert input to big matrix</span>
0047 <span class="comment">% and spit out trial number</span>
0048 
0049 spikewindows=[];
0050 spiketimes=[];
0051 spikeifr=[];
0052 trialnum=[];
0053 spike_data=[];
0054 
0055 <span class="comment">% use ifr as a clustering feature</span>
0056 
0057 <span class="keyword">if</span> iscell(SPIKEWINDOWS)
0058     <span class="keyword">for</span> i=1:length(SPIKEWINDOWS)
0059 
0060 
0061         [samples,trials]=size(SPIKEWINDOWS{i});
0062 
0063         <span class="comment">% interpolate to 50 kHz</span>
0064     
0065         spikewindows=[spikewindows SPIKEWINDOWS{i}];
0066         spiketimes=[spiketimes SPIKETIMES{i}];
0067 
0068         ifr_tmp=[];
0069         padded_spikes=[-inf SPIKETIMES{i} inf];
0070         <span class="keyword">for</span> j=2:length(padded_spikes)-1
0071             
0072             curr_spike=padded_spikes(j);
0073             next_spike=min(padded_spikes(padded_spikes&gt;padded_spikes(j)))-curr_spike;
0074             prev_spike=curr_spike-max(padded_spikes(padded_spikes&lt;padded_spikes(j)));
0075             ifr_tmp(j-1)=1/(min(next_spike,prev_spike)/sr); <span class="comment">% isi is the time from the closest spike, before or after</span>
0076         
0077         <span class="keyword">end</span>
0078 
0079         spikeifr=[spikeifr;ifr_tmp(:)];
0080         [samples trials]=size(SPIKEWINDOWS{i});
0081         trialnum=[trialnum;repmat(i,trials,1)];
0082 
0083     <span class="keyword">end</span>
0084 <span class="keyword">else</span>
0085 
0086     spikewindows=SPIKEWINDOWS;
0087     spiketimes=SPIKETIMES;
0088 
0089     ifr_tmp=[];
0090     padded_spikes=[-inf spiketimes inf];
0091     
0092     <span class="keyword">for</span> j=2:length(padded_spikes)-1
0093 
0094         curr_spike=padded_spikes(j);
0095         next_spike=min(padded_spikes(padded_spikes&gt;padded_spikes(j)))-curr_spike;
0096         prev_spike=curr_spike-max(padded_spikes(padded_spikes&lt;padded_spikes(j)));
0097         ifr_tmp(j-1)=(1/min(next_spike,prev_spike)/sr); <span class="comment">% isi is the min spike distance</span>
0098     <span class="keyword">end</span>
0099 
0100     spikeifr=ifr_tmp(:);
0101 
0102     [samples,trials]=size(SPIKEWINDOWS);
0103     trialnum=repmat(1,trials,1);
0104 <span class="keyword">end</span>
0105 
0106 TRIALS=trialnum;
0107 
0108 [samples,trials]=size(spikewindows);
0109 
0110 expansion=interpolate_fs/sr;
0111 interpspikes=zeros(samples*expansion,trials);
0112 
0113 <span class="comment">% take the time vector and expand to 2*fs (from 25k to 50k)</span>
0114 
0115 timepoints=[1:samples]';
0116 newtimepoints=linspace(1,samples,expansion*samples)';
0117 
0118 parfor i=1:trials
0119     interpspikes(:,i)=sinc(newtimepoints(:,ones(size(timepoints)))-timepoints(:,ones(size(newtimepoints)))')*spikewindows(:,i);
0120     <span class="comment">%interpspikes(:,i)=spline(timepoints,spikewindows(:,i),newtimepoints);</span>
0121 <span class="keyword">end</span>
0122 
0123 <span class="comment">%spikewindows=interpspikes;</span>
0124 
0125 parfor i=1:trials
0126     [wavecoef(:,i),l]=wavedec(interpspikes(:,i),4,<span class="string">'haar'</span>); <span class="comment">% 4-level wavelet decomposition</span>
0127 <span class="keyword">end</span>
0128 
0129 [coeffs,trials]=size(wavecoef);
0130 
0131 <span class="keyword">for</span> i=1:coeffs
0132 
0133     <span class="comment">% remove points &gt; +/- 3 std per quiroga et al 2004</span>
0134 
0135     testpoints=wavecoef(i,:);
0136 
0137     cutoff=3*std(testpoints);
0138 
0139     <span class="comment">% apparently overlapping spikes create outliers that corrupt the KS stat</span>
0140 
0141     testpoints(testpoints&lt;-cutoff)=[];
0142     testpoints(testpoints&gt;cutoff)=[];
0143 
0144     <span class="comment">% need to compute deviation from normality take max of empirical cdf and normcdf</span>
0145     <span class="comment">% with same mean and variance</span>
0146 
0147     <span class="comment">% samplecdf</span>
0148 
0149     <span class="keyword">if</span> length(testpoints(testpoints~=NaN))&lt;1
0150         normdev(i)=-inf;
0151         negentropy(i)=-inf;
0152         <span class="keyword">continue</span>;
0153     <span class="keyword">end</span>
0154 
0155     [fx,x]=ecdf(testpoints);
0156 
0157     <span class="comment">% evaluate normal cdf at same mean and variance as data</span>
0158 
0159     samplemean=mean(testpoints);
0160     samplestd=std(testpoints);
0161 
0162     gx=normcdf(x,samplemean,samplestd);
0163 
0164     <span class="comment">% deviation, ks statistic</span>
0165 
0166     normdev(i)=[max(abs(fx-gx))];
0167 
0168     normentropy=-sum(gx.*log2(gx+eps));
0169     obsentropy=-sum(fx.*log2(fx+eps));
0170 
0171     negentropy(i)=[normentropy-obsentropy]; <span class="comment">% an alternative measure</span>
0172 
0173 <span class="keyword">end</span>
0174 
0175 normdev(normdev==1)=0;
0176 [val,loc]=sort(normdev,<span class="string">'descend'</span>);
0177 
0178 <span class="keyword">if</span> length(loc)&gt;=maxcoeffs
0179     sortcoeffs=loc(1:maxcoeffs);
0180 <span class="keyword">else</span>
0181     sortcoeffs=loc;
0182 <span class="keyword">end</span>
0183 
0184 <span class="keyword">for</span> i=1:length(sortcoeffs)
0185     spike_data=[spike_data wavecoef(sortcoeffs(i),:)'];
0186 <span class="keyword">end</span>
0187 
0188 <span class="keyword">if</span> use_spiketime
0189     spike_data=[spike_data spiketimes];
0190 <span class="keyword">end</span>
0191 
0192 <span class="comment">% clustering, fit a Gaussian mixture model, first find the appropriate number of modes using</span>
0193 <span class="comment">% Akaike Information Criterion (AIC)</span>
0194 
0195 options=statset(<span class="string">'Display'</span>,<span class="string">'off'</span>);
0196 obj_fcn=[];
0197 
0198 clustnum=1:6;
0199 [datapoints,features]=size(spike_data);
0200 <span class="keyword">if</span> datapoints&lt;=features
0201     disp(<span class="string">'Too few spikes to fit'</span>);
0202     <span class="keyword">return</span>;
0203 <span class="keyword">end</span>
0204 
0205 <span class="comment">% gaussian mixture seems to work better than fcm</span>
0206 
0207 parfor i=1:length(clustnum)
0208 
0209     testobj=gmdistribution.fit(spike_data,clustnum(i),<span class="string">'Regularize'</span>,1,<span class="string">'Options'</span>,options);
0210     
0211     <span class="comment">%[center,u,obj_fcn]=fcm(spike_data,clustnum(i),[NaN NaN NaN 0]);</span>
0212     
0213     <span class="comment">% compute the partition coefficient, simply all membership indices squared and summed</span>
0214 
0215     <span class="comment">%partition_coef(i)=sum(sum(u.^2))/datapoints;</span>
0216 
0217     AIC(i)=testobj.AIC;
0218     logl(i)=testobj.NlogL;
0219     disp([ num2str(clustnum(i)) <span class="string">' clusters'</span>]);
0220 
0221     <span class="comment">%disp(['Partition coefficient ' num2str(partition_coef(i))]);</span>
0222     disp([ <span class="string">'AIC '</span> num2str(testobj.AIC)]) <span class="comment">% Akaike information criterion</span>
0223     disp([ <span class="string">'BIC '</span> num2str(testobj.BIC)]) <span class="comment">% Bayes information criterion</span>
0224 
0225 <span class="keyword">end</span>
0226 
0227 <span class="comment">% what gives us the max AIC?</span>
0228 
0229 <span class="comment">% max partition coefficient instead</span>
0230 
0231 <span class="comment">%[val,loc]=max(AIC);</span>
0232 <span class="comment">%[val,loc]=max(partition_coef);</span>
0233 
0234 <span class="keyword">for</span> i=1:length(logl)-2
0235     secondderiv(i)=logl(i+2)+logl(i)-2*logl(i+1);
0236 <span class="keyword">end</span>
0237 x=clustnum(2:end-1);
0238 
0239 [val,loc]=max(secondderiv); <span class="comment">% maximum derivative in log-likelihood over k</span>
0240 nclust=x(loc);
0241 
0242 disp([<span class="string">'Will use '</span> num2str(nclust) <span class="string">' clusters'</span>]);
0243 
0244 testobj=gmdistribution.fit(spike_data,nclust,<span class="string">'Regularize'</span>,1,<span class="string">'Options'</span>,options);
0245 [idx,nlogl,P]=cluster(testobj,spike_data);
0246 
0247 <span class="comment">%[center,u,obj_fcn]=fcm(spike_data,nclust,[NaN NaN NaN 0]);</span>
0248 <span class="comment">% place all points with posterior probability &lt;cutoff in the same junk cluster</span>
0249 
0250 counter=1;
0251 <span class="keyword">for</span> i=1:datapoints
0252 
0253     <span class="comment">%[membership(i),idx(i)]=max(u(:,i)); % take posterior probability of the chosen cluster</span>
0254                         <span class="comment">% given observation i as the measure of &quot;membership&quot;</span>
0255     membership(i)=P(i,idx(i));
0256 
0257     <span class="keyword">if</span> membership(i)&lt;outlier_cutoff
0258         idx(i)=nclust+1; <span class="comment">% assign new &quot;junk cluster&quot;</span>
0259         counter=counter+1;
0260     <span class="keyword">end</span>
0261 <span class="keyword">end</span>
0262 
0263 disp([ num2str(counter) <span class="string">' outliers'</span>]);
0264 clusters=unique(idx);
0265 
0266 <span class="keyword">for</span> i=1:length(nclust)
0267     idx(idx==clusters(i))=i;    
0268 <span class="keyword">end</span>
0269 
0270 <span class="comment">% return labels, and windows and ISI sorted by cluster IDX</span>
0271 
0272 LABELS=idx;
0273 
0274 [uniq_trial trial_boundary trial_group]=unique(trialnum);
0275 trial_boundary=[1;trial_boundary];
0276 
0277 <span class="keyword">for</span> i=1:length(clusters)
0278 
0279     WINDOWS{i}=interpspikes(:,LABELS==i);
0280 
0281     spikeisitmp=[];
0282 
0283     <span class="keyword">for</span> j=1:length(uniq_trial)
0284         
0285         <span class="comment">% all spike times in this trial</span>
0286         
0287         currtrial=spiketimes(trial_boundary(j):trial_boundary(j+1));
0288 
0289         <span class="comment">% now all spike ids from this trial</span>
0290 
0291         currlabels=LABELS(trialnum==uniq_trial(j));
0292 
0293         <span class="comment">% spike times for this cluster</span>
0294 
0295         currtrial=currtrial(currlabels==clusters(i));
0296 
0297         currisi=(diff(currtrial)); <span class="comment">% isi in msec</span>
0298         spikeisitmp=[spikeisitmp;currisi(:)];
0299     <span class="keyword">end</span>
0300 
0301 
0302     ISI{i}=spikeisitmp; <span class="comment">% convert to msec</span>
0303 <span class="keyword">end</span></pre></div>
<hr><address>Generated on Thu 19-Jul-2012 21:29:37 by <strong><a href="http://www.artefact.tk/software/matlab/m2html/" title="Matlab Documentation in HTML">m2html</a></strong> &copy; 2005</address>
</body>
</html>